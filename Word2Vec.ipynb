{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNwGVwCHTSXTtC/uv1DsFnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JINYUHOON/JINYUHOON/blob/main/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls-z2YDNzPYo"
      },
      "source": [
        "import os,sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks',my_path)\n",
        "sys.path.insert(0,my_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jnyv7b03FDi"
      },
      "source": [
        "형태소 : 의미를 가지는 요소로서는 더이상 분석 할 수 없는 가장 작은 말의 단위.\n",
        "KoNLPy는 시중에 공개된 hannanum, kkma, okt, komoran, mecab 다섯개 형태소 분석기를 한꺼번에 묶어서 편리하게 사용할 수 있도록 한 패키지.\n",
        "\n",
        "okt\n",
        "- morphs (phrase, norm=False, stem=False)\n",
        "\n",
        "Parse phrase to morphemes\n",
        "- nouns(phrase)\n",
        "- phrases(phrase)\n",
        "- pos(phrase, norm=False, stem=False, join=False)\n",
        "매개변수:\n",
        "norm == If True, normalize tokens.\n",
        "stem == If True, stem tokens.\n",
        "join == If True, returns joined sets of morph and tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvU2WzxX3D0F"
      },
      "source": [
        "# 형태소 분석으로 문장을 단어로 분할\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "print('형태소:',okt.morphs('단독입찰보다 복수입찰의 경우'))\n",
        "print('명사:',okt.nouns('유일하게 항공기 체계 종합개발 경험을 갖고 있는 KAI는'))\n",
        "print('구문',okt.phrases('날카로운 분석과 신뢰감 있는 진행으로'))\n",
        "print('품사',okt.pos('이것도 되나욬ㅋㅋ?'))\n",
        "print('norm옵션:',okt.pos('이것도 되나욬ㅋㅋ',norm=True))\n",
        "print('stem옵션:',okt.pos('이것도 되나욬ㅋㅋ',norm=True,stem=True))\n",
        "print('join옵션:',okt.pos('이것도 되나욬ㅋㅋ',norm=True,stem=True,join=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPKyVe6O-UOk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKfTB9eM6CnO"
      },
      "source": [
        "print('1. 명사만 추출: ',okt.nouns('나는 오늘 방콕에 가고싶다'))\n",
        "print('2. 원형만 추출: ',okt.pos('나는 오늘 방콕에 갔다',stem=True))\n",
        "print('3. 형태소 추출: ',okt.morphs('친절한 코치와 재미있는 친구들이 있는 도장에 가고 싶다.'))\n",
        "print('4. 형태소/태그 추출: ',okt.pos('나는 오늘도 장에 가고 싶다',norm=True,stem=True,join=True))\n",
        "print('5. 정규화,원형 추출: ',okt.pos('나는 오늘 장에 가고 싶을깤ㅋㅋ?',norm=True,stem=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1mx60XnF6cl"
      },
      "source": [
        "import re\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "okt= Okt()\n",
        "\n",
        "text = '''김웅 국민의힘 의원이 고위공직자범죄수사처(공수처)의 압수수색 영장을 취소해 달라며 신청한 준항고 사건을 담당할 재판부가 정해졌다.\n",
        "13일 서울중앙지방법원은 형사31단독(김찬년 판사) 재판부에 김 의원의 준항고 사건을 배당했다고 밝혔다.\n",
        "준항고는 사법기관의 처분에 불복해 법원에 이의를 제기하는 절차다. 법원이 영장 취소 결정을 내리면 공수처는 영장을 재발부받아야 한다.\n",
        "김웅 의원 측은 \"공수처의 압수수색 영장 집행 과정에서 위법성이 있기 때문에 영장을 취소해달라는 취지의 준항고장을 접수했다\"고 밝힌 바 있다.\n",
        "김 의원 측은 공수처가 김 의원과 변호사의 입회 전에 일부 범죄사실만 언급한 채 영장을 집행하고, 압수물 대상에 적시되지 않은 보좌관과 비서관의 \n",
        "PC 및 서류를 조사하고 PC 자료 추출 과정에서도 혐의와 관계가 없는 '오수' 등의 검색어로 검색했다는 점을 문제 삼고 있다.\n",
        "'''\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub('[0-9]+','',text)\n",
        "    text = re.sub('[A-Za-z]+','',text)\n",
        "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "text = clean_text(text)\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAE-RV7RNICq"
      },
      "source": [
        "pos_text = okt.pos(text)\n",
        "noun_list = []\n",
        "for word, tag in pos_text:\n",
        "    if tag == 'Noun':\n",
        "        noun_list.append(word)\n",
        "\n",
        "print(noun_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy5XpwSNP7fF"
      },
      "source": [
        "import codecs\n",
        "from bs4 import BeautifulSoup\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "fp = codecs.open('/content/drive/MyDrive/cakd3 colab/textmining/dataset/BEXX0003.txt','r',encoding='utf-16')\n",
        "\n",
        "soup = BeautifulSoup(fp,'html.parser')\n",
        "body = soup.select_one('body > text')\n",
        "text = body.getText()\n",
        "\n",
        "okt = Okt()\n",
        "word_dic = {}\n",
        "lines = text.split('\\n')\n",
        "for line in lines:\n",
        "    malist = okt.pos(line)\n",
        "    for word in malist:\n",
        "        if word[1] == 'Noun':\n",
        "            if not (word[0] in word_dic):\n",
        "                word_dic[word[0]] = 0\n",
        "            word_dic[word[0]] += 1 # 카운트하기\n",
        "\n",
        "keys = sorted(word_dic.items(), key=lambda x:x[1], reverse=True)\n",
        "for word, count in keys[:50]:\n",
        "    print('{0}({1})'.format(word,count),end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GryYTOFatgS"
      },
      "source": [
        "!pip install --target-$my_path gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pRO5rAVRKwD"
      },
      "source": [
        "import codecs\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from konlpy.tag import Okt\n",
        "from gensim.models import word2vec\n",
        "\n",
        "okt = Okt()\n",
        "results =[]\n",
        "lines= text.split('\\n')\n",
        "for line in lines:\n",
        "    malist = okt.pos(line, norm=True, stem=True)    # 형태소 분석 # 단어의 기본형 사용\n",
        "    r=[]\n",
        "    for word in malist:\n",
        "        if not word[1] in ['Josa', 'Eomi', 'Punctuation']:  # 어미/조사/구두점 등은 대상에서 제외\n",
        "            r.append(word[0])\n",
        "            \n",
        "    rl= (' '.join(r)).strip()   # \" \"를 이용해서 r의 리스트 값들을 합치고 좌우의 빈칸 제거\n",
        "    results.append(rl)\n",
        "    \n",
        "# 파일로 출력\n",
        "wakati_file= '/content/drive/MyDrive/cakd3 colab/textmining/dataset/toji.wakati'\n",
        "with open(wakati_file,'w', encoding='utf-8') as fp:\n",
        "    fp.write('\\n'.join(results))\n",
        "    \n",
        "# W2V 모델 만들기\n",
        "data = word2vec.LineSentence(wakati_file)\n",
        "model= word2vec.Word2Vec(data, size=200, window=10,\\\n",
        "                        hs=1, min_count=2, sg=1)\n",
        "model.save('/content/drive/MyDrive/cakd3 colab/textmining/dataset/toji.model')\n",
        "print('ok')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3e8bnNtf__a"
      },
      "source": [
        "model = word2vec.Word2Vec.load('/content/drive/MyDrive/cakd3 colab/textmining/dataset/toji.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TuAxPt8gVIp"
      },
      "source": [
        "model.wv.most_similar(positive=['집'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}