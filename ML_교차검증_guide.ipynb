{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e1393e",
   "metadata": {},
   "source": [
    "## 교차검증\n",
    "\n",
    "- 학습용 데이터와 테스트용 데이터를 분리해서 모데링 및 평가를 수행하는 방식은 과적합에 취약한 약점을 가질 수 있다.\n",
    "- 과적합은 모델이 학습 데이터에만 과도하게 최적화되어 실제 예측을 다른 데이터로 수행할 떄 예측 성능이 과도하게 떨어 지는 것을 의미한다.\n",
    "- 고정된 테스트 데이터로만 평가를 하게되면 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 편향되게 모델을 유도하는 경향이 발생한다.\n",
    "- 이러한 문제점을 개선하기 위하여 교차 검증을 이용해 다양한 학습과 평가를 수행한다.\n",
    "\n",
    "\n",
    "## K 폴드\n",
    "\n",
    "- K개의 데이터 폴드 세트를 만들어서 K번 만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법\n",
    "- 데이터 세트를 K등분 , 학습 데이터와 검증 데이터 세트를 K 번 변경하면서 학습과 검증을 수행한 결과를 평균해서 평과 결과 산출\n",
    "- 사이킷런의 KFold와 StratifiledKFold 클래스를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c22d077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "iris.keys()\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "\n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "pred = dt_clf.predict(train_data)\n",
    "\n",
    "accuracy_score(train_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269f5901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=1)\n",
    "\n",
    "dt_clf.fit(X_train,y_train)\n",
    "split_predict = dt_clf.predict(X_test)\n",
    "accuracy_score(y_test,split_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99fc256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차검증 정확도 : 1.0, 학습데이터크기 : 120, 검증 데이터 크기: 30\n",
      "\n",
      "#2 교차검증 정확도 : 0.9667, 학습데이터크기 : 120, 검증 데이터 크기: 30\n",
      "\n",
      "#3 교차검증 정확도 : 0.8667, 학습데이터크기 : 120, 검증 데이터 크기: 30\n",
      "\n",
      "#4 교차검증 정확도 : 0.9333, 학습데이터크기 : 120, 검증 데이터 크기: 30\n",
      "\n",
      "#5 교차검증 정확도 : 0.7333, 학습데이터크기 : 120, 검증 데이터 크기: 30\n",
      "\n",
      "## 평균 검증 정확도:  0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "\n",
    "kfold = KFold(n_splits = 5)\n",
    "cv_accuracy = []\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "for train_index,test_index in kfold.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    accuracy = np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차검증 정확도 : {1}, 학습데이터크기 : {2}, 검증 데이터 크기: {3}'\n",
    "         .format(n_iter, accuracy , train_size, test_size))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('\\n## 평균 검증 정확도: ',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c23d08",
   "metadata": {},
   "source": [
    "### Stratified K폴드\n",
    "\n",
    "- 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K폴드 방식\n",
    "- 불균형한 분포도를 가진 레이블 데이터 집합은 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것을 의미한다.\n",
    "  대출 사기 데이터를 예측하는 경우 대부분의 데이터가 정상 데이터이므로 대출 사기 레이블의 비율이 아주 적게 될 수 있으며 레이블 값 1이 특정\n",
    "  개별 반복별 학습/테스트 데이터 세트에는 상대적으로 많이 들어가고 다른 데이터 세트에는 그렇지 않을 수가 있다.\n",
    "- 대출 사기 레이블이 1인 레코드는 비록 건수는 작지만 알고리즘이 대출 사기를 예측하기 위한 중요한 파처를 가지고 있으므로 중요한 데이터 세트로서\n",
    "  원본 데이터와 유사한 대출 사기 레이블 값의 분포를 학습/테스트 세트에도 유지하는게 중요하다.\n",
    "- Stratified KFold는 KFold가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배 하지 못하는 경우의 문제를 해결해준다.\n",
    "- 일반적으로 분류에서의 교차검증은 Stratified KFold로 분할되어야 한다.\n",
    "- 회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자이기 떄문에 결정값별로 분포를 정하는 것이 의미가 없으므로 Stratified KFold가 지원되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6021d5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "763e326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차검증 : 1\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "##교차검증 : 2\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "##교차검증 : 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print('##교차검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87a0e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증:1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증:2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증:3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skt = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skt.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train  = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증:{0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제\n",
    "# KFold 대신 StratifiedKFold를 적용하여 상기건을 평가하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3900a7a9",
   "metadata": {},
   "source": [
    "### cross_val_score()\n",
    "\n",
    "- 사이킷런이 제공하는 교차검증을 좀 더 편리하게 수행할 수있는 대표적인 API 이다\n",
    "- KFold의 일련의 과정을 한꺼번에 수행해준다.\n",
    "- 주요 파라미터는 estimator,X,y,scroing,cv이다.\n",
    "- cross_val_score()는 내부적으로 StratifiedKFold를 이용한다\n",
    "- cross_val_score()는 하나의 평가 지표만 가능하나 corss_validate()는 여러 개의 평가 지표를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2675e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도:  [0.98 0.92 1.  ]\n",
      "평균:  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "data = iris.data\n",
    "label = iris.target\n",
    "\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도: ',np.round(scores,4))\n",
    "print('평균: ',np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa790c1",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "\n",
    "- 하이퍼 파라미터는 ML알고리즘의 주요 구성 요소이며 이 값을 조정해 알고리즘의 예측 성능을 개선할 수 있다.\n",
    "- 사이킷런은 GridSearchCV API를 이용해 Classifier나 Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서\n",
    "  편리하게 최적의 파라미터를 도출 할 수있는 방안을 제공한다\n",
    "- GridSearchCV 는 교차 검증을 기반으로 이 하이퍼파라미터의 최적 값을 찾게 해준다. 즉 데이터 세트를 cross_validation을 위한\n",
    "  학습/테스트 세트로 자동분할한 뒤에 하이퍼 파라미터 그리드에 기술된 모든 파라미터를 순차적으로 적용해 최적의 파라미터를 찾을 수 있게 해준다.\n",
    "- CV가 3회, 6개의 파라미터 조합이라면 총 18회의 학습/평가가 이루어진다.\n",
    "- 주요 파라미터 : estimator , param_grid, scroing, cv, refit\n",
    "    - param_grid : estimator 튜닝을 위해 파라미터명과 사용될 여러 파라미터값을 지정\n",
    "    - refit : 디폴트가 True이며 True로 생성 시 가장 최적의 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f5ae57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier() 0.9333333333333333\n",
      "LogisticRegression() 0.9555555555555556\n",
      "SVC() 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# 과제\n",
    "# Q. iris 데이터셋을 GridSearchCV를 이용하여 수행하세요\n",
    "# - randomforest, logisticRegression, svm\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "iris.keys()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
    "                                                   test_size=0.3, random_state=121) \n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "\n",
    "models = [rfc,lr,svc]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(model, accuracy_score(y_test,pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db729ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = svc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4f009ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parameter grid for parameter (C) needs to be a list or numpy array, but got (<class 'float'>). Single values need to be wrapped in a list with one element.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4fd3f693755e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgrid_rfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgrid_rfc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, estimator, param_grid, scoring, n_jobs, refit, cv, verbose, pre_dispatch, error_score, return_train_score)\u001b[0m\n\u001b[0;32m   1282\u001b[0m             return_train_score=return_train_score)\n\u001b[0;32m   1283\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m         \u001b[0m_check_param_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_check_param_grid\u001b[1;34m(param_grid)\u001b[0m\n\u001b[0;32m    398\u001b[0m             if (isinstance(v, str) or\n\u001b[0;32m    399\u001b[0m                     not isinstance(v, (np.ndarray, Sequence))):\n\u001b[1;32m--> 400\u001b[1;33m                 raise ValueError(\"Parameter grid for parameter ({0}) needs to\"\n\u001b[0m\u001b[0;32m    401\u001b[0m                                  \u001b[1;34m\" be a list or numpy array, but got ({1}).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                                  \u001b[1;34m\" Single values need to be wrapped in a list\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Parameter grid for parameter (C) needs to be a list or numpy array, but got (<class 'float'>). Single values need to be wrapped in a list with one element."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "grid_rfc = GridSearchCV(svc,param_grid = svc_params)\n",
    "grid_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665904b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abff79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc5344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3036e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
